{
  "alias": "video/1382/using-celery-with-social-networks",
  "category": "DjangoCon 2012",
  "copyright_text": "Creative Commons Attribution license (reuse allowed",
  "description": "Twitter conditionally rate limits based on IP address rather than access\ntoken even when one is provided for some of its API calls. Facebook has\nat least 10 unique error messages to indicate a bad or expired access\ntoken (that I've found so far). LinkedIn's pagination has an occasional\noff-by-one bug resulting in an endless list of 1-user pages. Let's face\nit: interfacing with social networks is tricky. Celery helps, but to\nprovide stable, reliable, and fast social features for your website,\nyou'll need an arsenal of strategies and tools to get you the rest of\nthe way there.\n\nBy the end of this talk, you'll understand how to set up tasks to\nquickly serve users with massive networks by employing intelligent\ndistribution. You'll be able to design robust processes to handle\ninconsistencies or instabilities in 3rd party APIs. And you'll know how\nto have confidence that the work you intend to do gets done, regardless\nof external rate limits, pagination design, or API call dependency\nchains.\n\nThis talk is intended for people who have basic familiarity with celery\nand would like to learn more about how to take advantage of it for\nlarge, distributed task loads.\n\nOutline\n-------\n\nI. Intro\n\nA. 3rd party interfaces are hard\n\n::\n\n      * Speed\n\n        * Much slower than local data\n        * Users may still expect near-immediate results\n\n      * Rate limits\n\n        * Different rules for every service\n        * Need to handle reactive & proactive as some don't publish rates\n\n      * Instability\n\n        * Outages (yes, Facebook does go down)\n        * Random failures\n\nB. Why Celery?\n\n::\n\n      * Asynchronous\n      * Distributed\n      * Fault tolerant\n\nII.  Task Organization\n\n     A. Small, atomic tasks (1 API call per task) B. Minimal message\n     state\n\n     -  Primitive types only (no model instances!)\n     -  Defer as much data access to the task itself as possible\n\n     C. Create Task subclasses for common patterns D. Whenever possible,\n     make tasks idempotent\n\nIII. Task Distribution\n\n     A. Managing pagination\n\n     ::\n\n         * For a known set size\n\n           * Where limit/offset is supported, launch all page tasks simlutaneously\n           * Otherwise, 1 page launches the next as soon as the next cursor is obtained\n\n         * For an unknown set size\n\n           * Set max simultaneous pages\n           * Task is terminal if blank, otherwise launches page w/ offset + max pages\n\n         * Setting page size is an art, not a science\n\n           * Minimize the number of api calls when possible\n           * Avoid long-running tasks by setting a timeout ceiling\n           * Avoid the temptation to pass API data to dependent tasks\n\n     B. Tracking task dependencies (\"Done?\" is difficult for distributed\n     systems)\n\n     ::\n\n         * Use an external backend to store a dependency tree\n         * Subclass ResultSet to evaluate the task state of the tree\n         * Requires ignore_result=False\n\nIV.  Rate Limiting\n\n     A. Problems\n\n     -  Celery's rate limiting doesn't do what you think it does\n     -  3rd party rate limits depend on many factors\n\n     B. Solution\n\n     -  For services with known rate limits:\n\n        -  Use an external backend to store rate limit counters\n        -  Increment counters based on rate limit factors per api call\n\n     -  For services with unknown rate limits:\n\n        -  Use an external backend to store rate limit backoff counters\n        -  Ramp up / ratchet down call rate by power law as api calls\n           fail/succeed\n\nV.   Failover\n\nA. Problems\n\n::\n\n      * Celery's countdown doesn't do what you think it does\n      * 3rd parties can fail in lots of \"interesting\" ways\n\nB. Solution\n\n::\n\n      * Implement native RabbitMQ alternative to countdown\n      * Create task base classes per social network to handle error conditions\n\nVI.   Multiple queues\n\n      A. Better control over task priority management & resource\n      distribution B. Not all social accounts are created equal\n      (handling whales & spikes) C. When you can't stream updates, use a\n      trickle queue\n\nVII.  Celerybeat considered harmful\n\n      A. Periodic task persistence gets out of sync with code B. Just 1\n      more process to manage C. Cron: it's just. not. that. hard.\n\nVIII. Debugging\n\n      A. Don't use \"always eager\" B. Logging, logging, logging C. Unit\n      tests are good, but integration tests save lives\n\nIXIV. Gotchas\n\n      A. Open socket prevents Celery soft timeout B. Celery soft timeout\n      doesn't retry the task C. If result state is not known, Celery\n      reports \"PENDING\"\n\n\n",
  "duration": null,
  "id": 1382,
  "language": "eng",
  "quality_notes": "",
  "recorded": "2012-09-05",
  "slug": "using-celery-with-social-networks",
  "speakers": [
    "David Gouldin"
  ],
  "summary": "Many web applications need to interface with social networks, and\ncelery, a Python distributed task queue library, is a great tool for the\njob. However, achieving speed and stability can be difficult. This talk\nwill cover task organization/distribution, rate limiting, failover, and\nother practices to aid in working with social networks at scale.\n",
  "tags": [
    "celery",
    "django"
  ],
  "thumbnail_url": "http://i.ytimg.com/vi/z751qhAzMb4/hqdefault.jpg",
  "title": "Using Celery with Social Networks",
  "videos": [
    {
      "length": 0,
      "type": "youtube",
      "url": "http://www.youtube.com/watch?v=z751qhAzMb4"
    }
  ]
}