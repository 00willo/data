{
  "description": "| Acquiring large datasets is quite simple these days on the internet,\n  but data is often noisy and most of the value often lies in combining,\n  connecting and merging multiple datasets from different sources.\n| This talk gives an overview of Probabilistic Record Matching, i.e. the\n  challenges posed when dealing with noisy data, how to normalize data\n  and how to match noisy records to each other.\n| The goal of the presentation is to give participants an understanding\n  of the possibilities and challenges of merging datasets, as well as\n  mention some of the amazing python libraries available.\n| Topics discussed: normalization of attributes, approximate string\n  matching, performance, similarity clustering\n",
  "duration": 1597,
  "recorded": "2016-11-06",
  "speakers": [
    "Johannes Ahlmann"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/1BjiTC5O_rc/hqdefault.jpg",
  "title": "How to Merge Noisy Datasets",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=1BjiTC5O_rc"
    }
  ]
}
